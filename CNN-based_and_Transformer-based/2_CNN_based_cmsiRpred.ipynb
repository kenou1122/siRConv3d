{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fe10fc-8e14-4d66-93a8-5ee47f83102c",
   "metadata": {},
   "source": [
    "# CNN-based cmsiRpred (Module A+B1+C)\n",
    "2-uni_v2-betaSearch-0327  \n",
    "UNI-v2_0327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23137496-0132-49c1-a6cd-e3d8d2c71f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_score, recall_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd23528-948f-480e-a250-3ee336ae3e93",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f952b4-2459-4d03-956b-7bc04b109673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured_encoded = pd.read_pickle('/home/ken/MyStorage/siRNA_2503/Data/df_structured_encoded_0326.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4a733d-8253-4539-b4df-fc67c839f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20626, 165) (2568, 165) (2588, 165)\n"
     ]
    }
   ],
   "source": [
    "df_structured_encoded_iid_trvl = df_structured_encoded[df_structured_encoded['dataset_usage']=='IID_trvl'].sample(frac=1)\n",
    "df_structured_encoded_iid_test = df_structured_encoded[df_structured_encoded['dataset_usage']=='IID_test']\n",
    "df_structured_encoded_ood_test = df_structured_encoded[df_structured_encoded['dataset_usage']=='OOD_test']\n",
    "print(df_structured_encoded_iid_trvl.shape,df_structured_encoded_iid_test.shape,df_structured_encoded_ood_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c9efa-0a40-422f-9181-43fcbee170b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fca077-a9db-49a8-9359-16babcbf0414",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e6cc11-694c-44f2-8d3b-10d4b4ff5ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class siRNA_dataset_CNN(Dataset):\n",
    "    def __init__(self, df_structured_encoded):\n",
    "        self.modiseq_tensor = torch.stack(list(df_structured_encoded['!!_modiseq_onehot3d'])).to(torch.float32)\n",
    "        struct_sense = torch.stack(list(df_structured_encoded['!!_nt_struct_type_sense_mea'].apply(lambda x: torch.flip(x,dims=[1])))) # convert sense to antisense\n",
    "        struct_antis = torch.stack(list(df_structured_encoded['!!_nt_struct_type_antis_mea']))\n",
    "        self.structs_tensor = torch.cat([struct_sense,struct_antis],axis=1).to(torch.float32)\n",
    "        df_tabular_encoded = df_structured_encoded.loc[:,df_structured_encoded.columns.str.contains(r'!\\w+!')]\n",
    "        self.features_tensor = torch.tensor(df_tabular_encoded.values).to(torch.float32)\n",
    "        label_tensor = torch.tensor(list(df_structured_encoded['mRNA_remaining_pct']))\n",
    "        self.label_tensor = label_tensor.reshape([len(label_tensor),1]).to(torch.float32)\n",
    "        self.domain_label_A = np.array(df_structured_encoded['publication_id'])\n",
    "    def __getitem__(self,index):\n",
    "        return (self.modiseq_tensor[index],self.structs_tensor[index],\n",
    "                self.features_tensor[index],self.label_tensor[index],\n",
    "                self.domain_label_A[index])\n",
    "    def __len__(self):\n",
    "        return self.modiseq_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c1bc63-e797-4ad3-ae58-1a0c0e5b55da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "modisiR_3dConv                           [256, 1]                  --\n",
       "├─OneHot3dConv: 1-1                      [256, 16]                 --\n",
       "│    └─Sequential: 2-1                   [256, 64, 2, 2, 2]        --\n",
       "│    │    └─Conv3d: 3-1                  [256, 64, 5, 5, 5]        150,592\n",
       "│    │    └─ReLU: 3-2                    [256, 64, 5, 5, 5]        --\n",
       "│    │    └─MaxPool3d: 3-3               [256, 64, 2, 2, 2]        --\n",
       "│    └─Sequential: 2-2                   [256, 16, 1, 1, 1]        --\n",
       "│    │    └─Conv3d: 3-4                  [256, 16, 2, 2, 2]        27,664\n",
       "│    │    └─ReLU: 3-5                    [256, 16, 2, 2, 2]        --\n",
       "│    │    └─MaxPool3d: 3-6               [256, 16, 1, 1, 1]        --\n",
       "├─Struct2dConv: 1-2                      [256, 16]                 --\n",
       "│    └─Sequential: 2-3                   [256, 32, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-7                  [256, 32, 5, 5]           12,576\n",
       "│    │    └─ReLU: 3-8                    [256, 32, 5, 5]           --\n",
       "│    └─Sequential: 2-4                   [256, 16, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-9                  [256, 16, 5, 5]           4,624\n",
       "│    │    └─ReLU: 3-10                   [256, 16, 5, 5]           --\n",
       "│    │    └─MaxPool2d: 3-11              [256, 16, 1, 1]           --\n",
       "├─TfxMLP: 1-3                            [256, 16]                 --\n",
       "│    └─Linear: 2-5                       [256, 256]                28,160\n",
       "│    └─ReLU: 2-6                         [256, 256]                --\n",
       "│    └─Linear: 2-7                       [256, 128]                32,896\n",
       "│    └─ReLU: 2-8                         [256, 128]                --\n",
       "│    └─Linear: 2-9                       [256, 16]                 2,064\n",
       "│    └─ReLU: 2-10                        [256, 16]                 --\n",
       "├─CombineMLP: 1-4                        [256, 1]                  --\n",
       "│    └─Linear: 2-11                      [256, 128]                6,272\n",
       "│    └─ReLU: 2-12                        [256, 128]                --\n",
       "│    └─Linear: 2-13                      [256, 128]                16,512\n",
       "│    └─ReLU: 2-14                        [256, 128]                --\n",
       "│    └─Linear: 2-15                      [256, 64]                 8,256\n",
       "│    └─ReLU: 2-16                        [256, 64]                 --\n",
       "│    └─Linear: 2-17                      [256, 1]                  65\n",
       "==========================================================================================\n",
       "Total params: 289,681\n",
       "Trainable params: 289,681\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.01\n",
       "==========================================================================================\n",
       "Input size (MB): 2.92\n",
       "Forward/backward pass size (MB): 20.58\n",
       "Params size (MB): 1.16\n",
       "Estimated Total Size (MB): 24.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OneHot3dConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=2,out_channels=64,kernel_size=(28,6,7),stride=1,padding=2,dilation=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=64,out_channels=16,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2,stride=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x_modiseq):\n",
    "        x = self.conv1(x_modiseq)\n",
    "        x = self.conv2(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "#summary(OneHot3dConv(), input_size=(BATCH_SIZE, 2, 28, 6,7))\n",
    "\n",
    "class Struct2dConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2,out_channels=32,kernel_size=(28,7),stride=1,padding=2,dilation=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,stride=1,padding=1,dilation=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=3)\n",
    "        )\n",
    "       \n",
    "    def forward(self,x_structs):\n",
    "        x = self.conv1(x_structs)\n",
    "        x = self.conv2(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "#summary(Struct2dConv(), input_size=(256, 2, 28, 7))\n",
    "\n",
    "class TfxMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(109,256)\n",
    "        self.actv1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(256,128)\n",
    "        self.actv2 = nn.ReLU()\n",
    "        self.dense3 = nn.Linear(128,16)\n",
    "        self.actv3 = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x): #output_onehot3dconv,dataload):    \n",
    "        x = self.dense1(x)\n",
    "        x = self.actv1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.actv2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.actv3(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "#summary(TfxMLP(), input_size=(BATCH_SIZE, 109))\n",
    "\n",
    "class CombineMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(48,128)\n",
    "        self.actv1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(128,128)\n",
    "        self.actv2 = nn.ReLU()\n",
    "        self.dense3 = nn.Linear(128,64)\n",
    "        self.actv3 = nn.ReLU()\n",
    "        self.actv_linear = nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.actv1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.actv2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.actv3(x)\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.actv_linear(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "#summary(CombineMLP(), input_size=(BATCH_SIZE, 48))\n",
    "\n",
    "class modisiR_3dConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.modiseq_conv = OneHot3dConv()\n",
    "        self.struct_conv = Struct2dConv()\n",
    "        self.tfx_mlp = TfxMLP()\n",
    "        self.combine_mlp = CombineMLP()\n",
    "    def forward(self,x_modiseq,x_struct,x_tfx):\n",
    "        x_modiseq_embed = self.modiseq_conv(x_modiseq)\n",
    "        x_struct_embed = self.struct_conv(x_struct)\n",
    "        x_tfx_embed = self.tfx_mlp(x_tfx)\n",
    "        x_combine = torch.cat([x_modiseq_embed,x_tfx_embed,x_struct_embed],axis=1)\n",
    "        y_pred = self.combine_mlp(x_combine)\n",
    "        return y_pred.reshape([len(y_pred),1])\n",
    "\n",
    "summary(modisiR_3dConv(), input_size=((BATCH_SIZE, 2,28,6,7),(BATCH_SIZE,2,28,7),(BATCH_SIZE,109)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1dddca-3645-4a14-b755-ca00771bb8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Ablation_modisiR_3dConv                  [256, 1]                  --\n",
       "├─OneHot3dConv: 1-1                      [256, 16]                 --\n",
       "│    └─Sequential: 2-1                   [256, 64, 2, 2, 2]        --\n",
       "│    │    └─Conv3d: 3-1                  [256, 64, 5, 5, 5]        150,592\n",
       "│    │    └─ReLU: 3-2                    [256, 64, 5, 5, 5]        --\n",
       "│    │    └─MaxPool3d: 3-3               [256, 64, 2, 2, 2]        --\n",
       "│    └─Sequential: 2-2                   [256, 16, 1, 1, 1]        --\n",
       "│    │    └─Conv3d: 3-4                  [256, 16, 2, 2, 2]        27,664\n",
       "│    │    └─ReLU: 3-5                    [256, 16, 2, 2, 2]        --\n",
       "│    │    └─MaxPool3d: 3-6               [256, 16, 1, 1, 1]        --\n",
       "├─Struct2dConv: 1-2                      [256, 16]                 --\n",
       "│    └─Sequential: 2-3                   [256, 32, 5, 5]           --\n",
       "│    │    └─Conv2d: 3-7                  [256, 32, 5, 5]           12,576\n",
       "│    │    └─ReLU: 3-8                    [256, 32, 5, 5]           --\n",
       "│    └─Sequential: 2-4                   [256, 16, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-9                  [256, 16, 5, 5]           4,624\n",
       "│    │    └─ReLU: 3-10                   [256, 16, 5, 5]           --\n",
       "│    │    └─MaxPool2d: 3-11              [256, 16, 1, 1]           --\n",
       "├─TfxMLP: 1-3                            [256, 16]                 --\n",
       "│    └─Linear: 2-5                       [256, 256]                28,160\n",
       "│    └─ReLU: 2-6                         [256, 256]                --\n",
       "│    └─Linear: 2-7                       [256, 128]                32,896\n",
       "│    └─ReLU: 2-8                         [256, 128]                --\n",
       "│    └─Linear: 2-9                       [256, 16]                 2,064\n",
       "│    └─ReLU: 2-10                        [256, 16]                 --\n",
       "├─Ablation_CombineMLP: 1-4               [256, 1]                  --\n",
       "│    └─Linear: 2-11                      [256, 128]                6,272\n",
       "│    └─ReLU: 2-12                        [256, 128]                --\n",
       "│    └─Linear: 2-13                      [256, 128]                16,512\n",
       "│    └─ReLU: 2-14                        [256, 128]                --\n",
       "│    └─Linear: 2-15                      [256, 64]                 8,256\n",
       "│    └─ReLU: 2-16                        [256, 64]                 --\n",
       "│    └─Linear: 2-17                      [256, 1]                  65\n",
       "==========================================================================================\n",
       "Total params: 289,681\n",
       "Trainable params: 289,681\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.01\n",
       "==========================================================================================\n",
       "Input size (MB): 2.92\n",
       "Forward/backward pass size (MB): 20.58\n",
       "Params size (MB): 1.16\n",
       "Estimated Total Size (MB): 24.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Ablation_CombineMLP(nn.Module):\n",
    "    def __init__(self,input_len):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(input_len,128)\n",
    "        self.actv1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(128,128)\n",
    "        self.actv2 = nn.ReLU()\n",
    "        self.dense3 = nn.Linear(128,64)\n",
    "        self.actv3 = nn.ReLU()\n",
    "        self.actv_linear = nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.actv1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.actv2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.actv3(x)\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.actv_linear(x)\n",
    "        return x.view(x.size(0),-1)\n",
    "\n",
    "class Ablation_modisiR_3dConv(nn.Module):\n",
    "    def __init__(self,ablation=(True,True,True)):\n",
    "        super().__init__()\n",
    "        self.ablation = ablation\n",
    "        if self.ablation[0]:self.modiseq_conv = OneHot3dConv()\n",
    "        if self.ablation[1]:self.struct_conv = Struct2dConv()\n",
    "        if self.ablation[2]:self.tfx_mlp = TfxMLP()\n",
    "        self.combine_mlp = Ablation_CombineMLP(16*sum(ablation))\n",
    "    def forward(self,x_modiseq,x_struct,x_tfx):\n",
    "        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        if self.ablation[0]:\n",
    "            x_modiseq_embed = self.modiseq_conv(x_modiseq)\n",
    "        else: x_modiseq_embed=torch.tensor([]).to(DEVICE)\n",
    "        \n",
    "        if self.ablation[1]:\n",
    "            x_struct_embed = self.struct_conv(x_struct)\n",
    "        else: x_struct_embed=torch.tensor([]).to(DEVICE)\n",
    "        \n",
    "        if self.ablation[2]:\n",
    "            x_tfx_embed = self.tfx_mlp(x_tfx)\n",
    "        else: x_tfx_embed=torch.tensor([]).to(DEVICE)\n",
    "        \n",
    "        x_combine = torch.cat([x_modiseq_embed,x_tfx_embed,x_struct_embed],axis=1)\n",
    "        y_pred = self.combine_mlp(x_combine)\n",
    "        return y_pred.reshape([len(y_pred),1])\n",
    "\n",
    "summary(Ablation_modisiR_3dConv((True,True,True)), input_size=((BATCH_SIZE, 2,28,6,7),(BATCH_SIZE,2,28,7),(BATCH_SIZE,109)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32727da-c4f8-4498-8e51-ed0d4f1707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VREX(dataload_TRAIN,env_list,beta,model,optimizer,criterion):\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    for x_batch_modiseq, x_batch_struct, x_batch_tfx, y_batch_lbl, x_domain_label_A in dataload_TRAIN:\n",
    "        risks = []\n",
    "        x_domain_label_A = np.array(x_domain_label_A)\n",
    "        for env in env_list:\n",
    "            env_mask = (x_domain_label_A == env)\n",
    "            if True not in env_mask: continue\n",
    "            x_env_modiseq = x_batch_modiseq[env_mask].to(DEVICE)\n",
    "            x_env_struct = x_batch_struct[env_mask].to(DEVICE)        \n",
    "            x_env_tfx = x_batch_tfx[env_mask].to(DEVICE)\n",
    "            y_env_lbl = y_batch_lbl[env_mask].to(DEVICE)\n",
    "            y_env_pred = model(x_env_modiseq,x_env_struct,x_env_tfx)\n",
    "            risks.append(criterion(y_env_pred,y_env_lbl))\n",
    "        \n",
    "        risks = torch.stack(risks)\n",
    "        risks_mean = torch.mean(risks)\n",
    "        risks_var = torch.var(risks)\n",
    "        \n",
    "        loss_batch = risks_mean + beta * risks_var\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train_total += risks_mean.item()\n",
    "    return loss_train_total/len(dataload_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc7ddb0-19c3-445e-b250-6b2bcd7cf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stdREX(dataload_TRAIN,env_list,beta,model,optimizer,criterion):\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    for x_batch_modiseq, x_batch_struct, x_batch_tfx, y_batch_lbl, x_domain_label_A in dataload_TRAIN:\n",
    "        risks = []\n",
    "        x_domain_label_A = np.array(x_domain_label_A)\n",
    "        for env in env_list:\n",
    "            env_mask = (x_domain_label_A == env)\n",
    "            if True not in env_mask: continue\n",
    "            x_env_modiseq = x_batch_modiseq[env_mask].to(DEVICE)\n",
    "            x_env_struct = x_batch_struct[env_mask].to(DEVICE)        \n",
    "            x_env_tfx = x_batch_tfx[env_mask].to(DEVICE)\n",
    "            y_env_lbl = y_batch_lbl[env_mask].to(DEVICE)\n",
    "            y_env_pred = model(x_env_modiseq,x_env_struct,x_env_tfx)\n",
    "            risks.append(criterion(y_env_pred,y_env_lbl))\n",
    "        \n",
    "        risks = torch.stack(risks)\n",
    "        risks_mean = torch.mean(risks)\n",
    "        #risks_var = torch.var(risks)\n",
    "        risks_var = torch.std(risks)\n",
    "        \n",
    "        loss_batch = risks_mean + beta * risks_var\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train_total += risks_mean.item()\n",
    "    return loss_train_total/len(dataload_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dcfa55f-d398-43bb-8c44-e5cf451bec83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ERM(dataload_TRAIN,model,optimizer,criterion):\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    \n",
    "    for x_batch_modiseq, x_batch_struct, x_batch_tfx, y_batch_lbl, x_domain_label_A in dataload_TRAIN:\n",
    "        x_batch_modiseq = x_batch_modiseq.to(DEVICE)\n",
    "        x_batch_struct = x_batch_struct.to(DEVICE)        \n",
    "        x_batch_tfx = x_batch_tfx.to(DEVICE)\n",
    "        y_batch_lbl = y_batch_lbl.to(DEVICE)\n",
    "        \n",
    "        y_batch_pred = model(x_batch_modiseq,x_batch_struct,x_batch_tfx)\n",
    "        loss_batch = criterion(y_batch_pred,y_batch_lbl)\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train += loss_batch.item()\n",
    "    return loss_train/len(dataload_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719e20c5-b0d5-4478-9f50-ba3cd66d5bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true, threshold=30):\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    y_true = y_true.clip(0,100)\n",
    "    y_pred = y_pred.clip(0,100)\n",
    "    \n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    y_true_binary = (y_true < threshold).astype(int)\n",
    "    y_pred_binary = (y_pred < threshold).astype(int)\n",
    "\n",
    "    mask = (y_pred >= 0) & (y_pred <= threshold)\n",
    "    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) if mask.sum() > 0 else 100\n",
    "\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    score = (1 - mae / 100) * 0.5 + (1 - range_mae / 100) * f1 * 0.5\n",
    "    \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc1fe8b-3ebb-4cab-9fc1-ae213aa1a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataload_VAL,model,criterion,threshold=30):\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    loss_val = 0\n",
    "    y_val_lbl = []\n",
    "    y_val_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch_modiseq, x_batch_struct, x_batch_tfx, y_batch_lbl, x_domain_label_A in dataload_VAL:\n",
    "            x_batch_modiseq = x_batch_modiseq.to(DEVICE)\n",
    "            x_batch_struct = x_batch_struct.to(DEVICE)        \n",
    "            x_batch_tfx = x_batch_tfx.to(DEVICE)\n",
    "            y_batch_lbl = y_batch_lbl.to(DEVICE)\n",
    "            \n",
    "            y_batch_pred = model(x_batch_modiseq,x_batch_struct,x_batch_tfx)\n",
    "            loss_batch = criterion(y_batch_pred,y_batch_lbl)\n",
    "\n",
    "            loss_val += loss_batch.item()\n",
    "            y_val_lbl.extend(y_batch_lbl.cpu().numpy())\n",
    "            y_val_pred.extend(y_batch_pred.cpu().numpy())\n",
    "        \n",
    "    y_val_pred = np.array(y_val_pred)\n",
    "    y_val_lbl = np.array(y_val_lbl)\n",
    "    model_score = calculate_metrics(y_val_pred, y_val_lbl,threshold)\n",
    "    return loss_val/len(dataload_VAL),model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e55c5-ac16-4674-bfdd-9885aad57be5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05b7cc-d6d5-4d61-8694-69a96d176baf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6a0964-3d7d-4825-8cfe-45260e5b7275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_TEST_IID = siRNA_dataset_CNN(df_structured_encoded_iid_test)\n",
    "dataset_TEST_OOD = siRNA_dataset_CNN(df_structured_encoded_ood_test)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a367a787-a64b-4706-b39d-659b9066fabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def cvmodel_test(model_list,dataset_TEST):\n",
    "    model4test = modisiR_3dConv()\n",
    "    test_score_list = []\n",
    "    for i in range(len(model_list)):\n",
    "        model4test.load_state_dict(model_list[i])\n",
    "        model4test.eval()\n",
    "        y_pred_TEST = model4test(dataset_TEST.modiseq_tensor,dataset_TEST.structs_tensor,dataset_TEST.features_tensor)\n",
    "        test_score = calculate_metrics(y_pred_TEST.detach().numpy(),dataset_TEST.label_tensor.detach().numpy())\n",
    "        print(test_score)\n",
    "        test_score_list.append(test_score)\n",
    "    return test_score_list\n",
    "\n",
    "def cv_train(rex_beta,model_type:str,ablation,df_structured_encoded_iid_trvl,dataset_TEST_IID,dataset_TEST_OOD):\n",
    "    lr = 0.002\n",
    "    EPOCHS = 40\n",
    "    BETA = rex_beta\n",
    "    BATCH_SIZE = 256\n",
    "    OVERSAMP = False\n",
    "\n",
    "    early_stop_score = 1\n",
    "    warm_up_epoch_num = 10\n",
    "    loss_tolerance_epoch_num = 5\n",
    "    env_list = df_structured_encoded_iid_trvl['publication_id'].unique()\n",
    "    \n",
    "    dataload_TEST_IID = DataLoader(dataset=dataset_TEST_IID,batch_size=BATCH_SIZE)\n",
    "    dataload_TEST_OOD = DataLoader(dataset=dataset_TEST_OOD,batch_size=BATCH_SIZE)\n",
    "\n",
    "    dataset_TRVL = siRNA_dataset_CNN(df_structured_encoded_iid_trvl)\n",
    "\n",
    "    kfold = KFold(n_splits=10,shuffle=True)\n",
    "    splits = kfold.split(dataset_TRVL)\n",
    "\n",
    "    model_list = []\n",
    "    cv_log = []\n",
    "    \n",
    "    print('rex_beta:',BETA)\n",
    "    print('Epoch','val','iid','ood','(val*','ood*)',sep='\\t')\n",
    "\n",
    "    for train_index, val_index in splits:\n",
    "\n",
    "        log_train = []\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        dataset_TRAIN = Subset(dataset_TRVL,train_index)\n",
    "        dataset_VAL = Subset(dataset_TRVL,val_index)\n",
    "\n",
    "        dataload_TRAIN = DataLoader(dataset=dataset_TRAIN,batch_size=BATCH_SIZE)\n",
    "        dataload_VAL = DataLoader(dataset=dataset_VAL,batch_size=BATCH_SIZE)\n",
    "\n",
    "        lowest_loss_epoch = {'loss_val':float(\"inf\"),'epoch':0}\n",
    "        best_score = -float('inf')\n",
    "        best_OOD = -float('inf')\n",
    "        model = Ablation_modisiR_3dConv(ablation)\n",
    "        optimizer = optim.AdamW([{'params':model.parameters(),'lr':lr}])\n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            start_time_epoch = time.time()\n",
    "            if model_type == 'vrex':\n",
    "                loss_train = train_VREX(dataload_TRAIN,env_list,BETA,model,optimizer,criterion)\n",
    "            elif model_type == 'erm':\n",
    "                loss_train = train_ERM(dataload_TRAIN,model,optimizer,criterion)\n",
    "            elif model_type == 'stdrex':\n",
    "                loss_train = train_stdREX(dataload_TRAIN,env_list,BETA,model,optimizer,criterion)\n",
    "            else: print('No such model type. Type should be erm, vrex or stdrex.')\n",
    "            loss_val,model_score = validate(dataload_VAL,model,criterion)\n",
    "            \n",
    "            _,test_score_iid = validate(dataload_TEST_IID,model,criterion)\n",
    "            _,test_score_ood = validate(dataload_TEST_OOD,model,criterion)\n",
    "\n",
    "            if epoch > warm_up_epoch_num:\n",
    "                if loss_val < lowest_loss_epoch['loss_val']:\n",
    "                    lowest_loss_epoch['epoch'] = epoch\n",
    "                    lowest_loss_epoch['loss_val'] = loss_val\n",
    "                elif (epoch-lowest_loss_epoch['epoch']) >= loss_tolerance_epoch_num:\n",
    "                    lowest_loss_epoch['epoch'] = epoch\n",
    "                    #lr = lr*0.5\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] *= 0.5\n",
    "                        \n",
    "            log_train.append((epoch,loss_train,loss_val,model_score,test_score_iid,test_score_ood,lr))\n",
    "            \n",
    "            if model_score > best_score:\n",
    "                best_score = model_score\n",
    "                best_OOD = test_score_ood\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print(f'\\r{epoch}\\t{model_score:.4f}\\t{test_score_iid:.4f}\\t{test_score_ood:.4f}\\t({best_score:.4f},{best_OOD:.4f})',sep='',end='')\n",
    "            \n",
    "            if best_score >= early_stop_score:\n",
    "                break\n",
    "        model_list.append(best_model)\n",
    "        cv_log.append(log_train)\n",
    "        print('')\n",
    "        \n",
    "    df_cv_log = pd.DataFrame()\n",
    "    for i in range(len(cv_log)):\n",
    "        df_log = pd.DataFrame(cv_log[i])\n",
    "        mindex = pd.MultiIndex.from_product([['Model_'+str(i)],['epoch','loss_train','loss_val','val_score','iid_score','ood_score','lr']])\n",
    "        df_log.columns = mindex\n",
    "        df_cv_log = pd.concat([df_cv_log,df_log],axis=1)\n",
    "        \n",
    "    return model_list,df_cv_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08ac46fd-0849-4948-9bec-1bcdf7a113e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state_dict_2cpu(PATH_SAVE,model_list,model):\n",
    "    os.mkdir(PATH_SAVE+'models')\n",
    "    for i in range(len(model_list)):\n",
    "        print(i,list(model_list[i].values())[0].device,end='\\t')\n",
    "        #model = modisiR_3dConv()\n",
    "        model.load_state_dict(model_list[i])\n",
    "        model.to('cpu')\n",
    "        print('to',list(model.state_dict().values())[0].device)\n",
    "        torch.save(model.state_dict(), PATH_SAVE+'models/state_dict_cpu_'+str(i)+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2070ba-9794-4e7a-84d5-b86b574f7deb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train_ERM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b848626-bc87-4907-b64c-abfd3f35b72c",
   "metadata": {},
   "source": [
    "ablation \\in \\{True,Flase\\}^3\n",
    "\n",
    "True: keep module\n",
    "False: ablate module\n",
    "\n",
    "ablation[0]: module B1-conv3d for sequence and modifications\n",
    "ablation[1]: module B1-conv2d for structure\n",
    "ablation[2]: experimental context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2629842-12f8-40e2-afc2-5e2272793718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rex_beta: None\n",
      "Epoch\tval\tiid\tood\t(val*\tood*)\n",
      "39\t0.8147\t0.8240\t0.5679\t(0.8147,0.5679)\n",
      "39\t0.8324\t0.8252\t0.5048\t(0.8326,0.5280)\n",
      "39\t0.8193\t0.8166\t0.6059\t(0.8273,0.6026)\n",
      "39\t0.8316\t0.8291\t0.5582\t(0.8340,0.5573)\n",
      "39\t0.8136\t0.8145\t0.6051\t(0.8183,0.6110)\n",
      "39\t0.8260\t0.8164\t0.5836\t(0.8260,0.5836)\n",
      "39\t0.8178\t0.8171\t0.5567\t(0.8192,0.5582)\n",
      "39\t0.8265\t0.8195\t0.5938\t(0.8294,0.6027)\n",
      "39\t0.8248\t0.8202\t0.6199\t(0.8268,0.6208)\n",
      "39\t0.8197\t0.8236\t0.6061\t(0.8206,0.6026)\n"
     ]
    }
   ],
   "source": [
    "ERM_model_list,ERM_cv_log = cv_train(None,'erm',(True,True,True),df_structured_encoded_iid_trvl,dataset_TEST_IID,dataset_TEST_OOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26e41ddb-44ac-46d9-9439-2e72105a035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5679281402018763\n",
      "0.5280390236450506\n",
      "0.6026027914395735\n",
      "0.5573469793955484\n",
      "0.611039572285671\n",
      "0.5835802169465945\n",
      "0.5581615777908702\n",
      "0.6027320146030849\n",
      "0.6208025716081216\n",
      "0.6025747556256172\n",
      "mean: 0.5834807643542008\n"
     ]
    }
   ],
   "source": [
    "ERM_cv_best_models_test_score = cvmodel_test(ERM_model_list,dataset_TEST_OOD)\n",
    "print('mean:',np.mean(np.array(ERM_cv_best_models_test_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e35911a1-d1c6-4c53-a4f0-ffffabc68c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cuda:0\tto cpu\n",
      "1 cuda:0\tto cpu\n",
      "2 cuda:0\tto cpu\n",
      "3 cuda:0\tto cpu\n",
      "4 cuda:0\tto cpu\n",
      "5 cuda:0\tto cpu\n",
      "6 cuda:0\tto cpu\n",
      "7 cuda:0\tto cpu\n",
      "8 cuda:0\tto cpu\n",
      "9 cuda:0\tto cpu\n"
     ]
    }
   ],
   "source": [
    "PATH_SAVE = '/home/ken/MyStorage/Models_out/CNN-ERM-40epo-TTT-10xCV-5834-250327'\n",
    "ablxn = (True,True,True)\n",
    "mdl_list = ERM_model_list\n",
    "cv_log = ERM_cv_log\n",
    "#################################\n",
    "if not os.path.exists(PATH_SAVE):\n",
    "    os.makedirs(PATH_SAVE)\n",
    "mdlsave = Ablation_modisiR_3dConv(ablxn)\n",
    "save_state_dict_2cpu(PATH_SAVE,mdl_list,mdlsave)\n",
    "######\n",
    "cv_log.to_pickle(PATH_SAVE+'/df_cv_log.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df83f27-331b-4376-a466-a9a1b4d98f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 40epo-5808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c267f8a-082d-467f-b150-feaafa49b76b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rex_beta: None\n",
      "Epoch\tval\tiid\tood\t(val*\tood*)\n",
      "39\t0.8173\t0.8162\t0.5896\t(0.8184,0.5997)\n",
      "39\t0.8108\t0.8209\t0.5533\t(0.8121,0.5592)\n",
      "39\t0.8078\t0.8214\t0.6030\t(0.8117,0.6006)\n",
      "39\t0.8269\t0.8270\t0.6040\t(0.8299,0.6049)\n",
      "39\t0.8015\t0.8070\t0.5129\t(0.8201,0.5165)\n",
      "39\t0.7821\t0.7989\t0.5925\t(0.8245,0.6062)\n",
      "39\t0.8180\t0.8187\t0.6070\t(0.8264,0.6064)\n",
      "39\t0.8146\t0.8208\t0.5652\t(0.8201,0.5723)\n",
      "39\t0.8219\t0.8195\t0.5689\t(0.8279,0.5793)\n",
      "39\t0.8306\t0.8261\t0.5614\t(0.8347,0.5634)\n"
     ]
    }
   ],
   "source": [
    "ERM_model_list,ERM_cv_log = cv_train(None,'erm',(True,True,True),df_structured_encoded_iid_trvl,dataset_TEST_IID,dataset_TEST_OOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b740c53c-51e8-48e4-9e32-a29cb3211d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5997471199210008\n",
      "0.5591965475587127\n",
      "0.6005657944442366\n",
      "0.604879484621486\n",
      "0.5165173763711366\n",
      "0.6061934393669389\n",
      "0.606446155603132\n",
      "0.5723382168056584\n",
      "0.5792832166469117\n",
      "0.5634480894436626\n",
      "mean: 0.5808615440782876\n"
     ]
    }
   ],
   "source": [
    "ERM_cv_best_models_test_score = cvmodel_test(ERM_model_list,dataset_TEST_OOD)\n",
    "print('mean:',np.mean(np.array(ERM_cv_best_models_test_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41da326e-0d89-40ab-bb1b-752ba11a58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cuda:0\tto cpu\n",
      "1 cuda:0\tto cpu\n",
      "2 cuda:0\tto cpu\n",
      "3 cuda:0\tto cpu\n",
      "4 cuda:0\tto cpu\n",
      "5 cuda:0\tto cpu\n",
      "6 cuda:0\tto cpu\n",
      "7 cuda:0\tto cpu\n",
      "8 cuda:0\tto cpu\n",
      "9 cuda:0\tto cpu\n"
     ]
    }
   ],
   "source": [
    "PATH_SAVE = '/home/ken/MyStorage/Models_out/CNN-ERM-40epo-TTT-10xCV-5808-250327'\n",
    "ablxn = (True,True,True)\n",
    "mdl_list = ERM_model_list\n",
    "cv_log = ERM_cv_log\n",
    "#################################\n",
    "if not os.path.exists(PATH_SAVE):\n",
    "    os.makedirs(PATH_SAVE)\n",
    "mdlsave = Ablation_modisiR_3dConv(ablxn)\n",
    "save_state_dict_2cpu(PATH_SAVE,mdl_list,mdlsave)\n",
    "######\n",
    "cv_log.to_pickle(PATH_SAVE+'/df_cv_log.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc23ff-6583-4f69-9d99-fd1ee4816bcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### VREX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a447c-ca97-4ac8-a85b-239d65bce348",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 40epo-6387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b51274eb-eff8-42f6-afa2-36c23f5602e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rex_beta: 1\n",
      "Epoch\tval\tiid\tood\t(val*\tood*)\n",
      "39\t0.5860\t0.5786\t0.6135\t(0.6382,0.6549)\n",
      "39\t0.5982\t0.5928\t0.5671\t(0.6450,0.6396)\n",
      "39\t0.6513\t0.6277\t0.6333\t(0.6643,0.6566)\n",
      "39\t0.5974\t0.6002\t0.6180\t(0.6607,0.6504)\n",
      "39\t0.5487\t0.5803\t0.5759\t(0.6424,0.6286)\n",
      "39\t0.6528\t0.6480\t0.6071\t(0.6541,0.6177)\n",
      "39\t0.6020\t0.6000\t0.6079\t(0.6295,0.6280)\n",
      "39\t0.5423\t0.5511\t0.5519\t(0.6079,0.6332)\n",
      "39\t0.6320\t0.6322\t0.6278\t(0.6386,0.6363)\n",
      "39\t0.5816\t0.5937\t0.5900\t(0.6319,0.6425)\n"
     ]
    }
   ],
   "source": [
    "VREX_1_model_list,VREX_1_cv_log = cv_train(1,'vrex',(True,True,True),df_structured_encoded_iid_trvl,dataset_TEST_IID,dataset_TEST_OOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69c977b7-0125-482c-bacd-08350f95b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6548543315475222\n",
      "0.6395922210036205\n",
      "0.6566229803476236\n",
      "0.6503841276557112\n",
      "0.628586882774321\n",
      "0.6176733745291099\n",
      "0.6280494159797089\n",
      "0.6331854241136192\n",
      "0.6362768648727204\n",
      "0.6424905160897494\n",
      "mean: 0.6387716138913706\n"
     ]
    }
   ],
   "source": [
    "VREX_cv_best_models_test_score = cvmodel_test(VREX_1_model_list,dataset_TEST_OOD)\n",
    "print('mean:',np.mean(np.array(VREX_cv_best_models_test_score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
